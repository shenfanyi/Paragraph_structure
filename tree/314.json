We introduce openXBOW, an open-source toolkit for the generation
of bag-of-words (BoW) representations from multimodal input. In
the BoW principle, word histograms were first used as features
in document classification, but the idea was and can easily be
adapted to, e.g., acoustic or visual descriptors, introducing a
prior step of vector quantisation. The openXBOW toolkit supports
arbitrary numeric input features and text input and concatenates
computed sub-bags to a final bag. It provides a variety of
extensions and options. To our knowledge, openXBOW is the first
publicly available toolkit for the generation of crossmodal
bags-of-words. The capabilities of the tool have been
exemplified in different scenarios: sentiment analysis in
tweets, classification of snore sounds, and time-dependent
emotion recognition based on acoustic, linguistic, and visual
information, where improved results over other feature
representations were observed.

[7, 2, []]
[7, 2, []]
[0, 2, []]
[4, 1, [", acoustic or visual descriptors, introducing a prior step of vector quantisation"]]
[9, 1, ["The openXBOW toolkit supports arbitrary numeric input features and text input and concatenates computed sub-bags to a final bag", "To our knowledge, openXBOW is the first publicly available toolkit for the generation of crossmodal bags-of-words"]]
[3, 2, []]
[6, 2, []]
[15, 1, ["We introduce openXBOW, an open-source toolkit for the generation of bag-of-words (BoW) representations from multimodal input", "In the BoW principle, word histograms were first used as features in document classification, but the idea was and can easily be adapted to, e", "The capabilities of the tool have been exemplified in different scenarios: sentiment analysis in tweets, classification of snore sounds, and time-dependent emotion recognition based on acoustic, linguistic, and visual information, where improved results over other feature representations were observed"]]
