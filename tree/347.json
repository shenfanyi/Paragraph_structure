Preserving privacy of continuous and/or high-dimensional data
such as images, videos and audios, can be challenging with
syntactic anonymization methods which are designed for discrete
attributes. Differentially privacy, which uses a more rigorous
definition of privacy loss, has shown more success in sanitizing
continuous data. However, both syntactic and differential
privacy are susceptible to inference attacks, i.e., an adversary
can accurately infer sensitive attributes from sanitized data.
The paper proposes a novel filter-based mechanism which
preserves privacy of continuous and high-dimensional attributes
against inference attacks. Finding the optimal utility-privacy
tradeoff is formulated as a min-diff-max optimization problem.
The paper provides an ERM-like analysis of the generalization
error and also a practical algorithm to perform minimax
optimization. In addition, the paper proposes a noisy minimax
filter which combines minimax filter and differentially-private
mechanism. Advantages of the method over purely noisy mechanisms
is explained and demonstrated with examples. Experiments with
several real-world tasks including facial expression
classification, speech emotion classification, and activity
classification from motion, show that the minimax filter can
simultaneously achieve similar or higher target task accuracy
and lower inference accuracy, often significantly lower than
previous methods.

[8, 1, []]
[6, 2, []]
[3, 2, []]
[0, 2, []]
[3, 2, []]
[7, 2, []]
[8, 1, ["Differentially privacy, which uses a more rigorous definition of privacy loss, has shown more success in sanitizing continuous data", "Finding the optimal utility-privacy tradeoff is formulated as a min-diff-max optimization problem"]]
[7, 2, []]
[7, 2, []]
[4, 2, []]
[19, 1, ["Preserving privacy of continuous and/or high-dimensional data such as images, videos and audios, can be challenging with syntactic anonymization methods which are designed for discrete attributes", "However, both syntactic and differential privacy are susceptible to inference attacks, i", "The paper proposes a novel filter-based mechanism which preserves privacy of continuous and high-dimensional attributes against inference attacks", "The paper provides an ERM-like analysis of the generalization error and also a practical algorithm to perform minimax optimization", "In addition, the paper proposes a noisy minimax filter which combines minimax filter and differentially-private mechanism", "Experiments with several real-world tasks including facial expression classification, speech emotion classification, and activity classification from motion, show that the minimax filter can simultaneously achieve similar or higher target task accuracy and lower inference accuracy, often significantly lower than previous methods"]]
