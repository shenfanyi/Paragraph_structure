Clustering is unsupervised and exploratory in nature. Yet, it
can be performed through penalized regression with grouping
pursuit, as demonstrated in Pan et al. (2013). In this paper, we
develop a more efficient algorithm for scalable computation and
a new theory of clustering consistency for the method. This
algorithm, called DC-ADMM, combines difference of convex (DC)
programming with the alternating direction method of multipliers
(ADMM). This algorithm is shown to be more computationally
efficient than the quadratic penalty based algorithm of Pan et
al. (2013) because of the former's closed-form updating
formulas. Numerically, we compare the DC- ADMM algorithm with
the quadratic penalty algorithm to demonstrate its utility and
scalability. Theoretically, we establish a finite-sample mis-
clustering error bound for penalized regression based clustering
with the $L_0$ constrained regularization in a general setting.
On this ground, we provide conditions for clustering consistency
of the penalized clustering method. As an end product, we put R
package 

[1, 2, []]
[3, 2, []]
[0, 2, []]
[6, 1, ["In this paper, we develop a more efficient algorithm for scalable computation and a new theory of clustering consistency for the method", "This algorithm is shown to be more computationally efficient than the quadratic penalty based algorithm of Pan et al", "Numerically, we compare the DC- ADMM algorithm with the quadratic penalty algorithm to demonstrate its utility and scalability", "On this ground, we provide conditions for clustering consistency of the penalized clustering method"]]
[7, 1, []]
[3, 2, []]
[3, 2, []]
[5, 2, []]
[7, 1, ["Yet, it can be performed through penalized regression with grouping pursuit, as demonstrated in Pan et al", "Theoretically, we establish a finite-sample mis- clustering error bound for penalized regression based clustering with the $L_0$ constrained regularization in a general setting"]]
[5, 2, []]
[4, 1, ["As an end product, we put R package"]]
