We consider the closely related problems of bandit convex
optimization with two-point feedback, and zero-order stochastic
convex optimization with two function evaluations per round. We
provide a simple algorithm and analysis which is optimal for
convex Lipschitz functions. This improves on Duchi et al.
(2015), which only provides an optimal result for smooth
functions; Moreover, the algorithm and analysis are simpler, and
readily extend to non-Euclidean problems. The algorithm is based
on a small but surprisingly powerful modification of the
gradient estimator.

[11, 1, ["We consider the closely related problems of bandit convex optimization with two-point feedback, and zero-order stochastic convex optimization with two function evaluations per round", "We provide a simple algorithm and analysis which is optimal for convex Lipschitz functions", "(2015), which only provides an optimal result for smooth functions; Moreover, the algorithm and analysis are simpler, and readily extend to non-Euclidean problems"]]
[4, 1, []]
[0, 2, []]
[5, 2, []]
[4, 1, ["The algorithm is based on a small but surprisingly powerful modification of the gradient estimator"]]
