We introduce Fisher consistency in the sense of unbiasedness as
a desirable property for estimators of class prior
probabilities. Lack of Fisher consistency could be used as a
criterion to dismiss estimators that are unlikely to deliver
precise estimates in test data sets under prior probability and
more general data set shift. The usefulness of this unbiasedness
concept is demonstrated with three examples of classifiers used
for quantification: Adjusted Count, EM-algorithm and CDE-
Iterate. We find that Adjusted Count and EM-algorithm are Fisher
consistent. A counter-example shows that CDE-Iterate is not
Fisher consistent and, therefore, cannot be trusted to deliver
reliable estimates of class probabilities.

[7, 1, []]
[11, 1, ["We introduce Fisher consistency in the sense of unbiasedness as a desirable property for estimators of class prior probabilities", "Lack of Fisher consistency could be used as a criterion to dismiss estimators that are unlikely to deliver precise estimates in test data sets under prior probability and more general data set shift", "A counter-example shows that CDE-Iterate is not Fisher consistent and, therefore, cannot be trusted to deliver reliable estimates of class probabilities"]]
[7, 1, ["The usefulness of this unbiasedness concept is demonstrated with three examples of classifiers used for quantification: Adjusted Count, EM-algorithm and CDE- Iterate", "We find that Adjusted Count and EM-algorithm are Fisher consistent"]]
[1, 2, []]
[6, 2, []]
